---
 title: include file
 description: include file
 author: eur
 ms.author: eric-urban
 ms.service: azure-ai-services
 ms.topic: include
 ms.date: 10/1/2023
 ms.custom: include
---

[!INCLUDE [Azure AI Studio preview](../includes/preview-ai-studio.md)]

To thoroughly assess the performance of your generative AI application when applied to a substantial dataset, you can initiate an evaluation process. During this evaluation, your application will be tested with the given dataset, and its performance will be quantitatively measured with both mathematical based metrics and AI-assisted metrics. This evaluation run will provide you with comprehensive insights into the application's capabilities and limitations. 

To carry out this evaluation, you can utilize the evaluation functionality in AI Studio, a comprehensive platform that offers tools and features for assessing the performance of your generative AI model. In AI Studio, you will be able to closely monitor the detailed evaluation metrics. 

By submitting your application for an evaluation in AI Studio, you can gain a deeper understanding of how it generates content, its accuracy, and how well it performs across a wide range of input scenarios. This detailed evaluation process will help you refine and enhance your generative AI application, ensuring it meets the highest standards and delivers the desired outcomes with large datasets. 

