---
title: Install and use the model management CLI for top Azure Machine Learning tasks
description: Learn how to install and use the model management CLI for the most common machine learning tasks in Azure Machine Learning.
services: machine-learning
author: Miguel.GonzalezFierro
ms.author: Miguel.GonzalezFierro
manager: haining
ms.reviewer: haining, mldocs, jmartens, jasonwhowell
ms.service: machine-learning
ms.workload: data-services
ms.topic: article
ms.date: 03/06/2018
---
# Install and use the model management CLI for top tasks in Azure Machine Learning

Azure Machine Learning services is an integrated, end-to-end data science and advanced analytics solution. 

![Azure Machine Learning CLI](media/cli-for-azure-machine-learning/flow.png)

## Get the CLI

To get this CLI, download and install Azure Machine Learning Workbench:​

+ For Windows: https://aka.ms/azureml-wb-msi ​
+ For Mac: https://aka.ms/azureml-wb-dmg ​​


## Start the CLI

From Azure Machine Learning Workbench, launch the CLI from the menu **File -> Open Command Prompt.**​

## Get command help on the CLI

Add `--debug` or `--help` to get extra info​ on the CLI commands.

For example:

```azurecli
az ml <xyz> --debug ​

az ml <xyz> --help
```

## Common machine learning CLI tasks

Here are some of the most common tasks you can perform with the CLI.

### Set up a compute target​

You can compute your ML model in local mode, in a Data Science VM (DSVM) or in a HDInsight cluster.​

Attach a DSVM target:​

```azurecli
az ml computetarget attach remotedocker -n <target name> -a <ip address or FQDN> -u <username> -w <password>​
``` 

Attach an HDInsight target:​

```azurecli
az ml computetarget attach cluster -n <target name> -a <cluster name, e.g. myhdicluster-ssh.azurehdinsight.net> -u <ssh username> -w <ssh password>​
```

Within the **aml_config** folder, you can change the conda dependencies. 

Also, you can operate with PySpark, Python or Python in a GPU DSVM. 

Define the Python operation mode as follows:
+ For Python, add `Framework:Python​` in `<target name>.runconfig` 
+ For PySpark, add `Framework:PySpark​` in `<target name>.runconfig` 
+ For Python in a GPU DSVM,
    + Add `Framework:Python​` in `<target name>.runconfig` 
    + Add `baseDockerImage: microsoft/mmlspark:plus-gpu-0.9.9 and nvidiaDocker:true​` in `<target name>.compute`

Prepare the compute target:​

```azurecli
az ml experiment prepare -c <target name>​
```

>[!TIP]
>To show and set your subscription​:<br/>
>`az account show​`<br/>
>`az account set –s "my subscription name" `​

### Submit a job

To submit a job to a remote target:​

```azurecli
az ml experiment submit -c <target name> myscript.py
```

### Work with Jupyter notebooks​

To start a Jupyter notebook:​

```azurecli
az ml notebook start​
```

This command starts a notebook in localhost. 

Work in local by selecting the kernel Python 3, or work in your remote VM by selecting the kernel `<target name>`.​


### Interact with and explore the run history

List the run history as follows:​

```azurecli
az ml history list -o table​
```

List all completed runs as follows:​
```azurecli
az ml history list --query "[?status=='Completed']" -o table​
```

Find runs with the best accuracy​ as follows:

```azurecli
az ml history list --query "@[?Accuracy != null] | max_by(@, &Accuracy).Accuracy"​
```
​

You can also download the files generated by each run. 

Promote a model saved in folder outputs as follows:​

```azurecli
az ml history promote -r <run id> -ap outputs/model.pkl -n <model name>​
```

Download that model as follows:​

```azurecli
az ml asset download -l assets/model.pkl.link -d <model folder path>​
```

### Configure your environment to operationalize

To set up your operationalization environment, you must create:​

> [!div class="checklist"]
> * A resource group ​
> * A storage account​
> * An Azure Container Registry (ACR)​
> * An Application insights account​
> * A Kubernetes deployment on an Azure Container Service (ACS) cluster​


Set up a local deployment for testing in a Docker container as follows:

```azurecli
az ml env setup -l <region, e.g. eastus2> -n <env name> -g <resource group>​
```

Set up an ACS cluster with Kubernetes​ as follows:

```azurecli
az ml env setup -l <region, e.g. eastus2> -n <env name> -g <resource group> --cluster​
```
​
Monitor deployment status during set up as follows:

```azurecli
az ml env show -n <environment name> -g <resource group>​
```
​

Set the environment to be used​ as follows:

```azurecli
az ml env set -n <environment name> -g <resource group>​
```

## Next steps



