---
title: "Troubleshooting batch endpoints"
titleSuffix: Azure Machine Learning
description: Learn how to troubleshoot and diagnostic errors with batch endpoints jobs
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: how-to
author: santiagxf
ms.author: fasantia
ms.date: 10/10/2022
ms.reviewer: larryfr
ms.custom: devplatv2
---

# Troubleshooting batch endpoints


## Common issues

### No module named 'azureml'

__Reason__: Azure Machine Learning Batch Deployments require the pakage `azureml-core` to be installed.

__Solution__: Add `azureml-core` to you conda dependencies file.


## The run() function in the entry script had timeout for [number] times

__Message logged__: `No progress update in [number] seconds. No progress update in this check. Wait [number] seconds since last update.`

__Reason__: Batch Deployments can be configured with a `timeout` value that indicates the amount of time the deployment shall wait for a single batch to be processed. If the execution of the batch takes more than such value, the task is aborted. Tasks that are aborted can be retried up to a maximum of times that can also be configured. If the `timeout` occurs on each retry, then the deployment job fails. These properties can be configured for each deployment.

__Solution__: Increase the `timemout` value of the deployment by updating the deployment. These properties are configured in the parameter `retry_settings`. By default, a `timeout=30` and `retries=3` is configured. When deciding the value of the `timeout`, take into consideration the number of files being processed on each batch and the size of each of those files. You can also decrease them to account for more mini-batches of smaller size and hence quicker to execute. 
