---
title: 'CLI (v2) core YAML syntax'
titleSuffix: Azure Machine Learning
description: Overview CLI (v2) core YAML syntax.
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: reference

author: mx-iao
ms.author: minxia
ms.date: 09/20/2021
ms.reviewer: laobri
---

# CLI (v2) core YAML syntax

Every Azure Machine Learning entity has a schematized YAML representation. You can create a new entity from a YAML configuration file with a `.yml` or `.yaml` extension. 

This article provides an overview of core syntax concepts you will encounter while configuring these YAML files.

[!INCLUDE [preview disclaimer](../../includes/machine-learning-preview-generic-disclaimer.md)]

## Creating an Azure ML entity from YAML
`az ml <entity> create --file entity.yml`

#### Short-form

The short-form syntax consists of the following:
* For assets: `azureml:<asset-name>:<asset-version>`
* For resources: `azureml:<resource-name>`

Azure ML will resolve this reference to the specified asset or resource in the workspace.

#### Long-form

The long-form syntax consists of the `azureml:` prefix plus the ARM resource ID of the entity:

`azureml:/subscriptions/<subscription-id>/resourceGroups/<resource-group>/providers/Microsoft.MachineLearningServices/workspaces/<workspace-name>/environments/<environment-name>/versions/<environment-version>`


## Azure ML data URI syntax

Azure ML offers a convenience data URI format to point to data in an Azure storage service. This can be used for scenarios where you need to specify a cloud storage location in your YAML file, such as creating an Azure ML model from file(s) in storage, or pointing to data to pass as input to a job.

To use this data URI format, the storage service you want to reference must first be registered as a datastore in your workspace. This format also consists of both a short-form and long-form syntax.

The Azure ML data URI format is supported in addition to the direct storage URI formats supported.

### Shortform

The shortform consists of a datastore in the current workspace and the path on the datastore to the file or folder you want to point to:

`azureml://datastores/<datastore-name>/paths/<path-on-datastore>/`

For example:
* `azureml://datastores/mydatastore/paths/mnist/`
* `azureml://datastores/mydatastore/paths/iris.csv/`

### Longform

The long-form syntax uses the following format:

`azureml://subscriptions/<subscription-id>/resourcegroups/<resource-group>/workspaces/<workspace-name>/datastores/<datastore-name>/paths/<path-on-datastore>/`


## Context and expression syntax for configuring Azure ML jobs and components

v2 job and component YAML files allow for the use of expressions to bind to contexts for different scenarios. The essential use case is for the author of the YAML file to use an expression for a value that might not be known at the time of authoring the configuration, but must be resolved at runtime.

Use the following syntax to tell Azure ML to evaluate an expression rather than treat it as a string:

`${{ <expression> }}`

The supported context scenarios are covered below.

### Parameterizing the `command` with the `inputs` and `outputs` contexts of a job

You can specify literal values, URI paths, and Azure ML datasets as inputs to a job. The `command` can then be parameterized with references to those input(s) using the `${{inputs.<input-name>}}` syntax. References to literal inputs will get resolved to the literal value at runtime, while references to data URI or Azure ML dataset inputs will get resolved to the download path or mount path (depending on the `mode` specified).

Likewise, outputs to the job can also be referenced in the `command`. For each named output specified in the `outputs` dictionary, Azure ML will autogenerate an output location based on the following templatized path: `{default-datastore}/azureml/{job-name}/{output-name}/`. Parameterizing the `command` with the `${{outputs.<output-name>}}` syntax will resolve that reference to the autogenerated path, so that your script can write files to that location from the job.

In the example below for a command job YAML file, the `command` is parameterized with two inputs, a literal input and a URI input, and one output. At runtime, the `${{inputs.learning_rate}}` expression will resolve to `0.01`, and the `${{inputs.iris}}` expression will resolve to the download path of the `iris.csv` file. `${{outputs.model_dir}}` will resolve to the mount path of the autogenerated output location.

```yaml
code:
  local_path: ./src
command: python train.py --lr ${{inputs.learning_rate}} --training-data ${{inputs.iris}} --model-dir ${{outputs.model_dir}}
environment: azureml:AzureML-Minimal:1
compute: azureml:cpu-cluster
inputs:
  learning_rate: 0.01
  iris:
    file: https://azuremlexamples.blob.core.windows.net/datasets/iris.csv
    mode: download
outputs:
  model_dir:
```

### Parameterizing the `command` with the `search_space` context for sweeping hyperparameters

You will also need to use this context syntax when performing hyperparameter tuning via sweep job, since the actual values of the hyperparameters are not known during job authoring time. When you run a sweep job, Azure ML will select hyperparameter values for each trial based on the `search_space`. In order to access those values in your training script, you must pass them in via the script's command-line arguments. To do so, use the `${{search_space.<hyperparameter>}}` syntax in the `trial.command`.

In the example below for a sweep job YAML file, the `${{search_space.learning_rate}}` and `${{search_space.boosting}}` references in `trial.command` will resolve to the actual hyperparameter values selected for each trial when the trial job is submitted for execution.

```yaml
type: sweep
sampling_algorithm: random
search_space:
  learning_rate:
    type: uniform
    min_value: 0.01
    max_value: 0.9
  boosting:
    type: choice
    values: ["gbdt", "dart"]
objective:
  goal: minimize
  primary_metric: test-multi_logloss
trial:
  code: 
    local_path: src 
  command: >-
    python train.py 
    --training-data ${{inputs.iris}}
    --lr ${{search_space.learning_rate}}
    --boosting ${{search_space.boosting}}
  environment: azureml:AzureML-Minimal:1
inputs:
  iris:
    file: https://azuremlexamples.blob.core.windows.net/datasets/iris.csv
    mode: download
compute: azureml:cpu-cluster
```

### Binding inputs and outputs between steps in a pipeline job

Context syntax is also used for binding inputs and outputs between steps in a pipeline job. For example, you can bind the input of one job (job #2) in a pipeline to the output of another job (job #1). This usage will signal to Azure ML the dependency flow of the pipeline graph, and job #2 will get executed after job #1, since the output of job #1 is required as an input for job #2.

For a pipeline job YAML file, the `inputs` and `outputs` sections of each child job are evaluated within the parent context (the top-level pipeline job). The `command`, on the other hand, will resolve to the current context (the child job).

There are two ways to bind inputs and outputs in a pipeline job:

**1) Bind to the top-level inputs and outputs of the pipeline job**

You can bind the inputs or outputs of a child job to the inputs/outputs of the top-level parent pipeline job using the following syntax: `${{inputs.<input-name>}}` or `${{outputs.<output-name>}}`. This reference resolves to the parent context, hence the top-level inputs/outputs. 

In the example below, the output (`model_dir`) of the final `train` step is bound to the top-level pipeline job output via `${{outputs.trained_model}}`

**2) Bind to the inputs and outputs of another child job (step)**

To bind the inputs/outputs of one step to the inputs/outputs of another step, use the following syntax: `${{jobs.<step-name>.inputs.<input-name>}}` or `${{jobs.<step-name>.outputs.<outputs-name>}}`. Again, this reference resolves to the parent context, so the context starts with `jobs.<step-name>`.

In the example below, the input (`clean_data`) of the `train` step is bound to the output (`prep_data`) of the `prep` step via `${{jobs.prep.outputs.prep_data}}`. The prepared data from the `prep` step will be used as the training data for the `train` step.


On the other hand, the context references within the `command` properties will resolve to the current context. For example, the `${{inputs.raw_data}}` reference in the `prep` step's `command` will resolve to the inputs of the current context, which is the `prep` child job. The lookup will be done on `prep.inputs`, so an input named `raw_data` must be defined there.


```yaml
type: pipeline
inputs:
outputs:
  trained_model:
jobs:
  prep:
    type: command
    inputs:
      raw_data:
        folder:
        mode: rw_mount
    outputs:
      prep_data: 
        mode: upload
    code:
      local_path: src/prep
    environment: azureml:AzureML-Minimal:1
    command: >-
      python prep.py 
      --raw-data ${{inputs.raw_data}} 
      --prep-data ${{outputs.prep_data}}
    compute: azureml:cpu-cluster
  train:
    type: command
    inputs: 
      clean_data: ${{jobs.prep.outputs.prep_data}}
    outputs:
      model_dir: $${{outputs.trained_model}}
    code: 
      local_path: src/train
    environment: azureml:AzureML-Minimal:1
    compute: azureml:gpu-cluster
    command: >-
      python train.py 
      --training-data ${{inputs.clean_data}} 
      --model-output ${{outputs.model_dir}}
```

### Parameterizing the `command` with the `inputs` and `outputs` contexts of a component

Similar to the `command` for a job, the `command` for a component can also be parameterized with references to the `inputs` and `outputs` contexts. In this case the reference is to the component's inputs and outputs. When the component is run in a job, Azure ML will resolve those references to the job runtime input and output values specified for the respective component inputs and outputs. Below is an example of using the context syntax for a command component YAML specification.

```yaml
code:
  local_path: ./src
command: python train.py --lr ${{inputs.learning_rate}} --training-data ${{inputs.iris}} --model-dir ${{outputs.model_dir}}
environment: azureml:AzureML-Minimal:1
inputs:
  learning_rate:
    type: number
    default: 0.01
    optional: true
  iris:
    type: path
outputs:
  model_dir:
    type: path
```

## Next steps

- [Install and use the CLI (v2)](how-to-configure-cli.md)
