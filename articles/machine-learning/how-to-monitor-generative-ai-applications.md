---
how-to-monitor-LLM-safety-quality---
title: Monitoring generative AI applications in production (preview)
titleSuffix: Azure Machine Learning
description: Monitor the safety and quality of generative AI deployed to production on Azure Machine Learning.
services: machine-learning
author: buchananwp
ms.author: wibuchan
ms.service: machine-learning
ms.subservice: mlops
ms.reviewer: mopeakande
reviewer: msakande
ms.topic: conceptual
ms.date: 09/06/2023
ms.custom: devplatv2
---

# Overview
Monitoring models in production is an essential part of the AI lifecycle: changes in data and consumer behavior can influence your LLM application over time, resulting in outdated AI systems, which can produce undesired results that can negatively impact business outcomes and expose organizations to compliance and reputational risks. 

AzureML model monitoring for generative AI applications makes it easier for you to monitor your LLM applications in production for safety and quality on a cadence to ensure it is delivering maximum business impact. This ultimately helps maintain the quality and safety of your generative AI applications, mitigating economic, reputational, and compliance risks. Capabilities and integrations include: 
- Collect production data using [Model Data Collector](../concept-data-collection.md) 
- Key [responsible AI evaluation metrics](#understanding-evaluation-metrics) such as groundedness, coherence, fluency, relevance, and similarity, which are interoperable with [AzureML prompt flow evaluation metrics](../prompt-flow/how-to-bulk-test-evaluate-flow.md). ​
- Ability to configure alerts for violations based on organizational targets and run monitoring on a recurring basis
- Consume results in a rich dashboard within a workspace in the Azure Machine Learning studio.
- Integration with AzureML prompt flow evaluation metrics, analysis of collected production data to provide timely alerts, and visualization of the metrics over time. ​

For overall model monitoring basic concepts, please refer to the [model monitoring concept article](../concept-model-monitoring.md)

In this article, you'll learn how to monitor a generative AI application backed by a managed online endpoint. The steps you'll take are:

- [Configure prerequisites](#prerequisites)
    - [Prerequisite #1: Create an Azure OpenAI resource](#create-an-azure-openai-resource)
    - [Prerequisite #2: Configure prompt flow for monitoring](#configure-prompt-flow-for-monitoring)
    - [Prerequisite #3: Configure access for your resources](#configure-access-for-your-resources)
- [Create your monitor](#create-your-monitor)
- [Visualize metrics in Studio UI](#visualize-metrics-in-studio-ui)

> [!IMPORTANT]
> Monitoring is currently in public preview. This preview is provided without a service-level agreement, and are not recommended for production workloads. Certain features might not be supported or might have constrained capabilities.
> For more information, see [Supplemental Terms of Use for Microsoft Azure Previews](https://azure.microsoft.com/support/legal/preview-supplemental-terms/).

# Understanding evaluation metrics 

## Evaluation metrics methodology
These metrics are generated by the following state-of-the-art GPT language models configured with specific evaluation instructions(prompt templates) which act as evaluators for sequence-to-sequence tasks. This technique has shown encouraging empirical results and high correlation with human judgement when compared to standard generative AI evaluation metrics. You can [learn more about the full suite of AzureML prompt flow evaluation metrics here](../prompt-flow/how-to-bulk-test-evaluate-flow.md). The following models are supported :
- GPT-3.5 Turbo
- GPT-4
- GPT-4-32k  

> [!NOTE] 
> Running evaluations with Azure OpenAI resources will incur usage on your account. 

## Metrics descriptions and use cases
### Groundedness
Groundedness evaluates how well the model's generated answers align with information from the input source. Answers are verified as claims against context in the user-defined ground truth source: even if answers are true (factually correct), if not verifiable against the source text, then it is scored as ungrounded. Responses verified as claims against “context” in the ground truth source (such as your input source or your database). 
- **Use it when:** You are worried your application generates information that is not included as part of the your generative AI's trained knowledge (AKA unverifiable information).|
- **How to read it:** If the model's answers are highly grounded, it indicates that the facts covered in the AI system's responses are verifiable by the input source or internal database. Conversely, low groundedness scores suggest that the facts mentioned in the AI system's responses may not be adequately supported or verifiable by the input source or internal database. In such cases, the model's generated answers could be based solely on its pre-trained knowledge, which may not align with the specific context or domain of the given input
- **Scale:** 1= "ungrounded", 5="perfect groundedness"

### Relevance
The relevance metric measures the extent to which the model's generated responses are pertinent and directly related to the given questions. When users interact with a generative AI model, they pose questions or input prompts, expecting meaningful and contextually appropriate answers.
- **Use it when:** You would like to achieve high relevance for your application's answers to enhance the user experience and utility of your generative AI systems.
- **How to read it:** Answers are scored in their ability to capture the key points of the question from the context in the ground truth source. If the model's answers are highly relevant, it indicates that the AI system comprehends the input and can produce coherent and contextually appropriate outputs. Conversely, low relevance scores suggest that the generated responses might be off-topic, lack context, or fail to address the user's intended queries adequately.    
- **Scale:** 1= "irrelevant", 5="perfect relevance"

### Coherence
Coherence evaluates how well the language model can produce output that flows smoothly, reads naturally, and resembles human-like language. How well does the bot communicate its messages in a brief and clear way, using simple and appropriate language and avoiding unnecessary or confusing information? How easy is it for the user to understand and follow the bot responses, and how well do they match the user's needs and expectations? 
- **Use it when:** You would like to test the readability and user-friendliness of your model's generated responses in real-world applications.
- **How to read it:** If the model's answers are highly coherent, it indicates that the AI system generates seamless, well-structured text with smooth transitions. Consistent context throughout the text enhances readability and understanding. Low coherence means that the quality of the sentences in a model's predicted answer is poor, and they do not fit together naturally. The generated text may lack a logical flow, and the sentences may appear disjointed, making it challenging for readers to understand the overall context or intended message. Answers are scored in their clarity, brevity, appropriate language, and ability to match defined user needs and expectations 
- **Scale:** 1= “incoherent”, 5=”perfectly coherent” 

### Fluency
Fluency evaluates the language proficiency of a generative AI's predicted answer. It assesses how well the generated text adheres to grammatical rules, syntactic structures, and appropriate usage of vocabulary, resulting in linguistically correct and natural-sounding responses. Answers are measured by the quality of individual sentences, and whether are they well-written and grammatically correct. This metric is particularly valuable when evaluating the language model's ability to produce text that adheres to proper grammar, syntax, and vocabulary usage. 
- **Use it when:** You would like to assess the grammatical and linguistic accuracy of the generative AI's predicted answers.
- **How to read it:** If the model's answers are highly coherent, it indicates that the AI system follows grammatical rules and uses appropriate vocabulary. Consistent context throughout the text enhances readability and understanding. Conversely, low fluency scores indicate struggles with  grammatical errors and awkward phrasing, making the text less suitable for practical applications.  
- **Scale:** 1=”halting”, 5=”perfect fluency” 

### Similarity 
Similarity quantifies the similarity between a ground truth sentence (or document) and the prediction sentence generated by an AI model. It is calculated by first computing sentence-level embeddings for both the ground truth and the model's prediction. These embeddings represent high-dimensional vector representations of the sentences, capturing their semantic meaning and context. 
- **Use it when:** You would like to objectively evaluate the performance of an AI model (for text generation tasks where you have access to ground truth desired responses). Ada similarity allows you to compare the generated text against the desired content.
- **How to read it:** Answers are scored for equivalencies to the ground-truth answer by capturing the same information and meaning as the ground-truth answer for the given question. A high Ada similarity score suggests that the model's prediction is very contextually similar to the ground truth, indicating accurate and relevant results. Conversely, a low Ada similarity score implies a mismatch or divergence between the prediction and the actual ground truth, potentially signaling inaccuracies or deficiencies in the model's performance.
- **Scale:** 1= "non-equivalence", 5="perfect equivalence"  

> [!NOTE] 
> Large language model evaluations are prone to the same bias that humans are. If possible, ensure there is a human-in-the-loop for production scenarios.

## Metrics requirements
- The following inputs (data column names) are required to measure generation safety & quality: 
* **prompt (aka question) text** - the original prompt given 
* **completion (aka answer) text** - the final completion from LLM API call that is returned
* **context text** - any context data that is sent to LLM API call together with original prompt. For example, if you hope to get search results only from certain certified information sources/website, you can define in the evaluation steps. This can be configured through PromptFlow. (optional)
* **ground truth text** - the user-defined text as the source of truth (optional)
- other part is the context/desired results.   

# Metric configuration
What parameters are configured in your data asset will dictate what metrics you can produce. 
| Metric | Prompt  | Completion |  Context | Ground truth |
| -- | -- | -- | -- | -- | 
| Coherence  | Required | Required | -- |  -- |  
| Fluency | Required | Required | -- | -- |  
| Groundedness | Required | Required | Required | -- |  
| Relevance | Required | Required | Required | -- |  
| Similarity | Required | Required | -- | Required |  

# Prerequisites
## Create an Azure OpenAI resource 
- TODO

## Configure prompt flow for monitoring
1. Create a workspace connection [following this guidance]((https://learn.microsoft.com/en-us/azure/machine-learning/prompt-flow/get-started-prompt-flow?view=azureml-api-2#connection)). **DO NOT** delete the connection once it's used in the flow. 
- This will represent your Azure OpenAI resource backing your application
1. Create a runtime [following this guidance] (https://learn.microsoft.com/en-us/azure/machine-learning/prompt-flow/how-to-create-manage-runtime?view=azureml-api-2)
clone a sample flow or create flow from scratch, specify the connection and runtime, run it.
1. After your promptflow run successfully completes, select "Deploy" and finish the deploy wizard by [following this guidance](https://learn.microsoft.com/en-us/azure/machine-learning/prompt-flow/how-to-deploy-for-real-time-inference?view=azureml-api-2) 
- Remember to grant permissions [following this guidance](https://learn.microsoft.com/en-us/azure/machine-learning/prompt-flow/how-to-deploy-for-real-time-inference?view=azureml-api-2#grant-permissions-to-the-endpoint) to the endpoint identity. If you use system-assigned identity, you need to assign "AzureML Data Scientist" role of workspace to the endpoint identity.
- Ensure your flow inputs are configured: "prompt" (aka "question")
- Ensure your desired flow outputs are being captured: "completion" (aka "answer")
- Ensure any additional optional outputs are collected: "context" or "ground truth" 
- Enable inferencing data collection, which uses AzureML's [Model Data Collector](https://learn.microsoft.com/en-us/azure/machine-learning/concept-data-collection?view=azureml-api-2)
1. The deployment creation may take more than 15 mins. After deployment creation finishes, you can test it in endpoint detail page UI.
1. Confirm your data is being collected in the "test" tab of your endpoint

## Configure access for your resources
Your Azure OpenAI resource will need to be manually configured with access policies to have the appropriate permissions. [Learn more here](../how-to-configure-monitoring-connection.md)

> [!IMPORTANT]
> During preview, the above permissions are required to configure your monitoring.  

# Create your monitor 
    - Change 'model task type' to 'prompt & completion'
    - Select deployed annotator model to create your monitoring signal  
    - Select target output dataset (inputs & outputs) 
    - Select metrics 
    
# Visualize metrics in Studio UI 
    - View the metrics over time 
    - View histogram of distributions 
    - View samples of violations 
   