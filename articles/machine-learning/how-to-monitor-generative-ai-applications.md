---
title: Monitoring generative AI applications in production (preview)
titleSuffix: Azure Machine Learning
description: Monitor the safety and quality of generative AI deployed to production on Azure Machine Learning.
services: machine-learning
author: buchananwp
ms.author: wibuchan
ms.service: machine-learning
ms.subservice: mlops
ms.reviewer: scottpolly
reviewer: s-polly
ms.topic: how-to
ms.date: 09/06/2023
ms.custom: devplatv2
---

# Monitoring AI applications
Monitoring models in production is an essential part of the AI lifecycle: changes in data and consumer behavior can influence your LLM application over time, resulting in outdated AI systems, which can produce undesired results that can negatively impact business outcomes and expose organizations to compliance and reputational risks. 

Azure Machine Learning model monitoring for generative AI applications makes it easier for you to monitor your LLM applications in production for safety and quality on a cadence to ensure it is delivering maximum business impact. This ultimately helps maintain the quality and safety of your generative AI applications, mitigating economic, reputational, and compliance risks. Capabilities and integrations include: 
- Collect production data using [Model Data Collector](concept-data-collection.md) 
- Key [responsible AI evaluation metrics](#understanding-evaluation-metrics) such as groundedness, coherence, fluency, relevance, and similarity, which are interoperable with [Azure Machine Learning prompt flow evaluation metrics](prompt-flow/how-to-bulk-test-evaluate-flow.md).
- Ability to configure alerts for violations based on organizational targets and run monitoring on a recurring basis
- Consume results in a rich dashboard within a workspace in the Azure Machine Learning studio.
- Integration with Azure Machine Learning prompt flow evaluation metrics, analysis of collected production data to provide timely alerts, and visualization of the metrics over time. â€‹

For overall model monitoring basic concepts, please refer to [Model monitoring with Azure Machine Learning (preview)](concept-model-monitoring.md).

In this article, you'll learn how to monitor a generative AI application backed by a managed online endpoint. The steps you'll take are:

- [Configure prerequisites](#prerequisites)
    - [Prerequisite #1: Create an Azure OpenAI resource](#create-and-configure-azure-openai-resource)
    - [Prerequisite #2: Configure prompt flow for monitoring](#configure-prompt-flow-for-monitoring)
- [Create your monitor](#create-your-monitor)
- [Visualize metrics in Studio UI](#visualize-metrics-in-studio-ui)

> [!IMPORTANT]
> Monitoring is currently in public preview. This preview is provided without a service-level agreement, and are not recommended for production workloads. Certain features might not be supported or might have constrained capabilities.
> For more information, see [Supplemental Terms of Use for Microsoft Azure Previews](https://azure.microsoft.com/support/legal/preview-supplemental-terms/).



## Understanding evaluation metrics 

### Evaluation metrics methodology
These metrics are generated by the following state-of-the-art GPT language models configured with specific evaluation instructions(prompt templates) which act as evaluators for sequence-to-sequence tasks. This technique has shown encouraging empirical results and high correlation with human judgement when compared to standard generative AI evaluation metrics. You can [understand the generative AI monitoring metrics and use-cases here](/concept-model-monitoring-generative-ai-evaluation-metrics.md) and [learn more about the full suite of AzureML prompt flow evaluation metrics here](../prompt-flow/how-to-bulk-test-evaluate-flow.md)  

> [!NOTE] 
> Running evaluations with Azure OpenAI resources will incur usage on your account. You will need an Azure OpenAI resource properly configued using the steps above. 

### Supported models
The following GPT models are supported as evaluator models:
- GPT-3.5 Turbo
- GPT-4
- GPT-4-32k  

## Prerequisites
### Create and configure Azure OpenAI resource 
- You must have an Azure OpenAI resource configured with a workspace connection. Follow the steps below to configure one. Your Azure OpenAI resource will need to be manually configured with access policies to have the appropriate permissions. Follow the instructions below [Learn more here](../how-to-configure-monitoring-connection.md)


### Configure a prompt flow deployment for monitoring
1. Create a workspace connection [following this guidance](https://learn.microsoft.com/en-us/azure/machine-learning/prompt-flow/get-started-prompt-flow?view=azureml-api-2#connection). **DO NOT** delete the connection once it's used in the flow. 
- This will represent your Azure OpenAI resource backing your application
1. Create a runtime [following this guidance](https://learn.microsoft.com/en-us/azure/machine-learning/prompt-flow/how-to-create-manage-runtime?view=azureml-api-2)
clone a sample flow or create flow from scratch, specify the connection and runtime, run it.
1. After your promptflow run successfully completes, select "Deploy" and finish the deploy wizard by [following this guidance](https://learn.microsoft.com/en-us/azure/machine-learning/prompt-flow/how-to-deploy-for-real-time-inference?view=azureml-api-2) 
    1. Remember to grant permissions [following this guidance](https://learn.microsoft.com/en-us/azure/machine-learning/prompt-flow/how-to-deploy-for-real-time-inference?view=azureml-api-2#grant-permissions-to-the-endpoint) to the endpoint identity. If you use system-assigned identity, you need to assign "AzureML Data Scientist" role of workspace to the endpoint identity.
    1. Ensure your flow inputs are configured: "prompt" (aka "question")
    1. Ensure your desired flow outputs are being captured: "completion" (aka "answer")
    1. Ensure any additional optional outputs are collected: "context" or "ground truth" 
    1. Enable inference data collection, which uses AzureML's [Model Data Collector](https://learn.microsoft.com/en-us/azure/machine-learning/concept-data-collection?view=azureml-api-2)
1. The deployment creation may take more than 15 mins.
1. After deployment creation finishes, confirm your data is being collected in the "test" tab of your endpoint.

> [!IMPORTANT]
> During preview, the above permissions are required to configure your monitoring, or your monitor will fail.  

## 1. Create your monitor 
1. ### Configure basic monitoring settings
    - A. Change 'model task type' to 'prompt & completion'
   :::image type="content" source="media/how-to-monitor-models/gsq-configure-basic-settings.png" alt-text="Screenshot showing how to configure basic monitoring settings for generative AI." lightbox="media/how-to-monitor-models/gsq-configure-basic-settings.png":::
1. ### Configure data asset
    No action is required. Monitoring will automatically join your model inputs and outputs, but you can override with a custom data asset if desired. 
    :::image type="content" source="media/how-to-monitor-models/gsq-configure-data-asset.png" alt-text="Screenshot showing how to configure your data asset for generative AI." lightbox="media/how-to-monitor-models/gsq-configure-data-asset.png":::

1. ### Select monitoring signals
    You will need to configure your workspace connection correctly, or you will see this: 
    :::image type="content" source="media/how-to-monitor-models/gsq-configure-signal1.png" alt-text="Screenshot showing an unconfigured monitoring signal." lightbox="media/how-to-monitor-models/gsq-configure-signal1.png":::
    
    - A. Configure workspace connection 
    - B. Enter your Azure OpenAI evaluator deployment name (Note: this is a preview feature and will be automated)
    - C. (optional) join your production data inputs & outputs
        - Your production model inputs and outputs will be automatically joined by the Monitoring service. You can customize this if needed, but no action is required. By default, the join column is 'correlationid' which is generated by Model Data Collector. 
    - D. (optional) Configure metric thresholds. 

        - An acceptable per-instance score is fixed at 3/5. You can adjust your passing rate as-needed.
        - #### Metric requirements
        - The following inputs (data column names) are required to measure generation safety & quality: 
        * **prompt (aka question) text** - the original prompt given 
        * **completion (aka answer) text** - the final completion from the API call that is returned
        * **context text** - any context data that is sent to the API call, together with original prompt. For example, if you hope to get search results only from certain certified information sources/website, you can define in the evaluation steps. This is an optional step that can be configured through PromptFlow.
        * **ground truth text** - the user-defined text as the "source of truth" (optional)
        
        - #### Metric configuration
        What parameters are configured in your data asset will dictate what metrics you can produce. 
        | Metric | Prompt  | Completion |  Context | Ground truth |
        | -- | -- | -- | -- | -- | 
        | Coherence  | Required | Required | -- |  -- |  
        | Fluency | Required | Required | -- | -- |  
        | Groundedness | Required | Required | Required | -- |  
        | Relevance | Required | Required | Required | -- |  
        | Similarity | Required | Required | -- | Required |  

    - E. Enter column names from your prompt flow. Standard names are ("prompt" | "completion" | "context" | "ground_truth") but you can configure it according to your data asset
    - F. (optional) Set sampling rate
    :::image type="content" source="media/how-to-monitor-models/gsq-configure-signal2.png" alt-text="Screenshot showing monitoring signal configurations." lightbox="media/how-to-monitor-models/gsq-configure-signal2.png":::

    - Once configured, your signal will no longer show an error, and you can proceed
    :::image type="content" source="media/how-to-monitor-models/gsq-configure-signal3.png" alt-text="Screenshot showing monitoring signal configurations." lightbox="media/how-to-monitor-models/gsq-configure-signal3.png":::

1. ### Configure notifications
    - No action is required. You can configure additional recipients on notifications if needed.
    :::image type="content" source="media/how-to-monitor-models/gsq-configure-notifications.png" alt-text="Screenshot showing monitoring notification configurations." lightbox="media/how-to-monitor-models/gsq-configure-notifications.png.png":::
    - gsq-configure-notifications.png

1. ### Confirm your monitoring configuration  
    When successfully congfiguired, your monitor should look like this:
    :::image type="content" source="media/how-to-monitor-models/gsq-confirm-configuration.png" alt-text="Screenshot showing a configured monitoring signal." lightbox="media/how-to-monitor-models/gsq-confirm-configuration.png":::

## 2. Confirm monitoring status
    If configured successfully, your monitoring pipeline will show the following: 
    :::image type="content" source="media/how-to-monitor-models/gsq-confirm-job-success.png" alt-text="Screenshot showing a completed monitoring job." lightbox="media/how-to-monitor-models/gsq-confirm-job-success.png":::


## 3. Visualize metrics in Studio UI 
1. View your monitor overview
    :::image type="content" source="media/how-to-monitor-models/gsq-monitor-overview.png" alt-text="Screenshot showing monitor overview." lightbox="media/how-to-monitor-models/gsq-monitor-overview.png":::
1. A. View metrics over time
1. B. View histogram of distributions 
    :::image type="content" source="media/how-to-monitor-models/gsq-monitor-signal-details.png" alt-text="Screenshot showing a signal details page." lightbox="media/how-to-monitor-models/gsq-monitor-signal-details.png":::
1. Resolve alerts by adjusting signal thresholds
    :::image type="content" source="media/how-to-monitor-models/gsq-monitor-signal-adjust-signal.png" alt-text="Screenshot adjusting signal thresholds." lightbox="media/how-to-monitor-models/gsq-monitor-signal-adjust-signal.png":::
   
## Next steps
<!---What next steps are appropriate?>
- 
-