---
title: Cognitive search for data extraction, natural language processing in Azure Search | Microsoft Docs
description: Data extraction, natural language processing (NLP) and image processing to create searchable content in Azure Search indexing using cognitive skills.
manager: cgronlun
author: HeidiSteen

ms.service: search
ms.devlang: NA
ms.topic: conceptual
ms.date: 05/04/2018
ms.author: heidist
---
# What is cognitive search?

Cognitive search is a preview feature of Azure Search, available on all tiers in South Central US and West Europe, that adds AI to indexing workloads. Data extraction, natural language processing, and image processing during indexing finds the latent information in  unstructured or non-searchable content and makes it searchable in Azure Search.

AI integration is through *cognitive skills* that enrich source documents through these various forms of processing, in route to a search index. 

![Cognitive search pipeline diagram](./media/cognitive-search-intro/cogsearch-architecture.png "Cognitive Search pipeline overview")

Skills can be predefined or custom:

+ Prefined skills are based on Cognitive Services APIs. Named Entity Recognition, Text Analytics, and OCR are just a few. 

+ Custom skills can be developed for specialized processing. Examples of custom skills might be a custom entity module or document classifier targeting a specific domain such as finance, scientific publications, or medicine.

> [!NOTE]
> Cognitive Search is in public preview, and skillset execution is currently offered for free. At a later time, the pricing for this capability will be announced.

## Components of cognitive search

You can think of cognitive search as a pipeline that pushes source documents through a sequence of operations, building an enriched version of source documents that ultimately find their way to an Azure Search index, accessed via search requests through all query types supported by Azure Search.  

Underneath, the engine driving the pipeline is an existing Azure Search *indexer*. Indexers crawl data from supported sources, add field mappings and logic, and push documents into a search index that you've defined in advance.

### Source data and document cracking phase

At the start of the pipeline, you have unstructured text or non-text content (such as image files, scanned document JPG files, audio files). Data must exist in an Azure data storage service that can be accessed by an indexer. Supported sources include Azure blob storage, Azure table storage, Azure SQL Database, and Azure Cosmos DB. Blobs can be image files, audio files, scanned documents, and so forth. Text-based content can be extracted from the following file types: PDFs, Word, PowerPoint, CSV files. For the full list, see [Supported formats](search-howto-indexing-azure-blob-storage.md#supported-document-formats).

### Cognitive skills and enrichment phase

Enrichment is implemented as *cognitive skills* that invoke atomic transformations. For example, once you have the textual representation of a PDF file, you could apply natural language processing in the form of an entity recognition skill, a language detection skill, or a key phrase extraction skill to break up undifferentiated text into semantically rich parts, consumable in search workloads. Altogether, the entire collection of skills used in your pipeline is called a *skillset*.  

Cognitive search provides [predefined cognitive skills](cognitive-search-predefined-skills.md) that can be consumed out of the box. The pipeline is also extensible. You can build custom skills from the ground up, and connect it as part of the skillset. For more information, see [Example: create a custom skill](cognitive-search-create-custom-skill-example.md) and [How to define a custom interface](cognitive-search-custom-skill-interface.md).

A skillset can be minimal or highly complex. A skillset determines not only the type of processing, but also the order of operations. A skillset plus the field mappings defined as part of an indexer determines the enrichment pipeline. For more information about pulling all of these pieces together, see [How to create a skillset](cognitive-search-defining-skillset.md).

### Enriched documents

Internally, the pipeline generates a collection of enriched documents. You can decide which parts of the enriched documents should be mapped to indexable fields in your search index. For example, if you applied the key phrases extraction and the entity recognition skills, then those new fields would become part of the enriched document, and they can be mapped to fields on your index.

### Search index and query-based access

When processing is finished, you have a search corpus consisting of enriched documents, fully text-searchable in Azure Search. Querying the index is how developers and users utilize the enriched content generated by the pipeline. 

The index is like any other you might create for Azure Search: you can supplement with custom analyzers, invoke fuzzy search queries, add filtered search, or experiment with scoring profiles to reshape the search results.

Indexes are generated from an index schema that defines the fields, attributes, and other constructs attached to a specific index, such as scoring profiles and synonym maps. Once an index is defined and populated, you can refresh it to pick up new and updated source documents. Enrichment steps are seamlessly integrated with the indexing workload; the same operations performed during initial data ingestion also occur in subsequent refresh operations.

<a name="feature-concepts"></a>

## Key features and concepts

| Concept | Description|
|---------|------------|
| Skillset | A top-level named resource containing a collection of skills. A skillset is the enrichment pipeline. |
| Cognitive skill | An atomic transformation in an enrichment pipeline. Often, it is a component that extracts or infers structure, and therefore augments an understanding of the input data. Almost always, the output is text-based and the processing is natural language processing or image processing that extracts or generates text from image inputs. Output can be mapped to a field in an index, or used as an input for a downstream enrichment. A skill is either predefined or custom. |
| Data extraction | Covers a broad range of processing, but as specifically related to cognitive search, the named entity recognition skill is most typically used to extract data (an entity) from a source that doesn't provide that information natively. |
| Image processing | Infers text from an image, such as the ability to recognize a landmark, or extracts text from an image. Common examples include OCR for lifting characters from a scanned document (JPEG) file, or recognizing a street name in a photograph containing a street sign. | 
| Natural language processing | Text processing for insights and information about text inputs.. Language detection, sentiment analysis, and key phrase extraction are skills that fall under natural language processing.  | 
| Document cracking | The process of extracting or creating text content from non-text sources during indexing. Optical character recognition (OCR) and audio-to-text translation are two examples. The data source providing source file location, and the indexer definition providing field mappings, are both key factors in document cracking. |
| Enriched documents | A transitory internal structure, not directly accessible in code. Enriched documents are generated during processing, but only final outputs are persisted in a search index. Field mappings determine which data elements are added to the index. |
| Indexer |  A crawler that extracts searchable data and metadata from an external data source and populates an index based on field-to-field mappings between the index and your data source for document cracking. For cognitive search enrichments, the indexer invokes a skillset, and contains the field mappings associating enrichment output to target fields in the index. The indexer definition contains all of the instructions and references for pipeline operations, and the pipeline is invoked when you run the indexer. |
| Data Source  | An object used by an indexer to connect to an external data source of supported types on Azure. |
| Index | A persisted search corpus in Azure Search, built from an index schema that defines field structure and usage. |


## Where do I start?

**Step 1: Create a search service in a region providing the APIs** 

+ South Central US
+ West Europe

**Step 2: Hands-on experience to master the workflow**

+ [Quickstart (portal)](cognitive-search-quickstart-blob.md)
+ [Tutorial (HTTP requests)](cognitive-search-tutorial-blob.md)
+ [Example custom skills (C#)](cognitive-search-create-custom-skill-example.md)

**Step 3: Review the API (REST only)**

Currently, only REST APIs are provided. Use `api-version=2017-11-11-Preview` on all requests. Use the following APIs to build a cognitive search solution. Only two APIs are added or extended for cognitive search. Other APIs have the same syntax as the generally available versions.

| REST API | Description |
|-----|-------------|
| [Create Data Source](https://docs.microsoft.com/rest/api/searchservice/create-data-source)  | A resource identifying an external data source providing source data used to create enriched documents.  |
| [Create Skillset (api-version=2017-11-11-Preview)](ref-create-skillset.md)  | A resource coordinating the use of [predefined skills](cognitive-search-predefined-skills.md) and [custom cognitive skills](cognitive-search-custom-skill-interface.md) used in an enrichment pipeline during indexing. |
| [Create Index](https://docs.microsoft.com/rest/api/searchservice/create-index)  | A schema expressing an Azure Search index. Fields in the index map to fields in source data or to fields manufactured during the enrichment phase (for example, a field for organization names created by entity recognition). |
| [Create Indexer (api-version=2017-11-11-Preview)](ref-create-skillset.md)  | A resource defining components used during indexing: including a data source, a skillset, field associations from source and intermediary data structures to target index, and the index itself. Running the indexer is the trigger for data ingestion and enrichment. The output is a search corpus based on the index schema, populated with source data, enriched through skillsets.  |
| [Reset Indexer](https://docs.microsoft.com/rest/api/searchservice/reset-indexer) | A command for rebuilding an index. Because pipeline development is an iterative process, plan for frequent index rebuilds.

**Checklist: A typical workflow**

1. Subset your Azure source data into a representative sample. Indexing takes time so start with a small, representative data set and then build it up incrementally as your solution matures.

1. Create a data source object in Azure Search to provide a connection string for data retrieval.

1. Create a skillset with enrichment steps.

1. Define the index schema. The *Fields* collection includes fields from source data. You should also stub out additional fields to hold generated values for content created during enrichment.

1. Define the indexer referencing the data source, skillset, and index.

1. Within the indexer, add *outputFieldMappings*. This section maps output from the skillset (in step 3) to the inputs fields in the index schema (in step 4).

1. Send *Create Indexer* (a POST request with an indexer definition in the request body) to create and run the indexer, invoking the pipeline.

1. Evaluate results and modify code to update skillsets, schema, or indexer configuration.

1. Reset the indexer before rebuilding the pipeline.

## Next steps

+ [Quickstart: Try cognitive search](cognitive-search-quickstart-blob.md)
+ [Tutorial: Enriched indexing of Azure blob content](cognitive-search-tutorial-blob.md)
+ [Example: creating a custom skill](cognitive-search-create-custom-skill-example.md)
+ [How to create a skillset or enrichment pipeline](cognitive-search-defining-skillset.md)
+ [How to define a custom interface](cognitive-search-custom-skill-interface.md)